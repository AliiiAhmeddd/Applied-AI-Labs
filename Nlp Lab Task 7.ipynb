{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90338c21",
   "metadata": {},
   "source": [
    "Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269adeb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(\"\\n--- Exercise 1: Part-of-Speech Tagging with NLTK ---\")\n",
    "\n",
    "text5 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens5 = word_tokenize(text5)\n",
    "pos_tags = nltk.pos_tag(tokens5)\n",
    "\n",
    "print(f\"Original text: '{text5}'\")\n",
    "print(f\"Tokens: {tokens5}\")\n",
    "print(f\"POS Tags:\")\n",
    "for word, tag in pos_tags:\n",
    "    print(f\"{word:<10} {tag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea892b",
   "metadata": {},
   "source": [
    "Ex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675d5c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "print(\"\\n--- Exercise 2: Dependency Parsing with SpaCy ---\")\n",
    "\n",
    "# Load SpaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text7 = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "doc = nlp(text7)\n",
    "\n",
    "print(f\"Original text: '{text7}'\")\n",
    "print(\"Dependency Parse:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12} POS={token.pos_:<8} DEP={token.dep_:<15} HEAD={token.head.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480cd7ec",
   "metadata": {},
   "source": [
    "Ex 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafc477",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n--- Exercise 3: Text Classification with scikit-learn ---\")\n",
    "\n",
    "# Sample dataset\n",
    "texts = [\n",
    "    \"This movie is fantastic and I love it!\",\n",
    "    \"What a terrible film, absolutely dreadful.\",\n",
    "    \"The acting was good, but the plot was boring.\",\n",
    "    \"A truly amazing experience, highly recommended.\",\n",
    "    \"I hated every minute of this movie, so bad.\",\n",
    "    \"It was an okay film, nothing special.\"\n",
    "]\n",
    "\n",
    "labels = ['positive', 'negative', 'neutral', 'positive', 'negative', 'neutral']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(\"Test sentences:\")\n",
    "print(X_test)\n",
    "print(\"\\nActual labels:\")\n",
    "print(y_test)\n",
    "print(\"\\nPredicted labels:\")\n",
    "print(predicted)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted, zero_division=0))\n",
    "\n",
    "# Predict new sentence\n",
    "new_sentence = \"I really enjoyed this production, very entertaining!\"\n",
    "prediction = text_clf.predict([new_sentence])\n",
    "\n",
    "print(f\"\\nNew sentence: '{new_sentence}'\")\n",
    "print(f\"Predicted sentiment: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a01d0",
   "metadata": {},
   "source": [
    "Challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c1576",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "paragraph = (\n",
    "    \"The film started with a strong opening and excellent visuals. \"\n",
    "    \"However, the storyline quickly became predictable and dull. \"\n",
    "    \"Despite a few good performances, the overall experience was disappointing.\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Challenge: Integrated NLP Pipeline ---\")\n",
    "print(f\"\\nParagraph:\\n{paragraph}\")\n",
    "\n",
    "print(\"\\nTokenization & POS Tagging:\")\n",
    "\n",
    "tokens = word_tokenize(paragraph)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "for word, tag in pos_tags:\n",
    "    print(f\"{word:<12} {tag}\")\n",
    "print(\"\\nDependency Parsing:\")\n",
    "\n",
    "doc = nlp(paragraph)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12} POS={token.pos_:<8} DEP={token.dep_:<15} HEAD={token.head.text}\")\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(paragraph)\n",
    "predictions = text_clf.predict(sentences)\n",
    "\n",
    "print(\"\\nSentence-level sentiment predictions:\")\n",
    "for sent, pred in zip(sentences, predictions):\n",
    "    print(f\"Sentence: {sent}\")\n",
    "    print(f\"Predicted sentiment: {pred}\\n\")\n",
    "\n",
    "# Majority vote for paragraph sentiment\n",
    "from collections import Counter\n",
    "overall_sentiment = Counter(predictions).most_common(1)[0][0]\n",
    "\n",
    "print(f\"Overall paragraph sentiment (majority vote): {overall_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a17b7",
   "metadata": {},
   "source": [
    "POS tagging identifies grammatical roles (nouns, verbs, adjectives).\n",
    "\n",
    "Dependency parsing shows how words relate syntactically.\n",
    "\n",
    "Text classification predicts sentiment using a trained Naive Bayes model.\n",
    "\n",
    "Since the classifier is sentence-based, the paragraph was split into sentences and classified individually.\n",
    "\n",
    "A majority vote was used to determine the overall sentiment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
